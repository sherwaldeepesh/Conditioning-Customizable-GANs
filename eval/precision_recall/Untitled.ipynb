{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c2ef138-5033-4532-9a15-ace190452862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dnnlib\n",
    "import hashlib\n",
    "import requests\n",
    "from typing import Any, List, Tuple, Union\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4084b5-dbdf-49db-bbea-be893891ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url(obj: Any) -> bool:\n",
    "    \"\"\"Determine whether the given object is a valid URL string.\"\"\"\n",
    "    if not isinstance(obj, str) or not \"://\" in obj:\n",
    "        return False\n",
    "    try:\n",
    "        res = requests.compat.urlparse(obj)\n",
    "        if not res.scheme or not res.netloc or not \".\" in res.netloc:\n",
    "            return False\n",
    "        res = requests.compat.urlparse(requests.compat.urljoin(obj, \"/\"))\n",
    "        if not res.scheme or not res.netloc or not \".\" in res.netloc:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da669163-9e78-44c5-9e82-3ec20139a130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://drive.google.com/uc?id=1fk6r8vetqpRShtEODXm9maDytbMkHLfa ... done\n"
     ]
    }
   ],
   "source": [
    "cache_dir: str = None\n",
    "num_attempts: int = 10\n",
    "verbose: bool = True\n",
    "url = 'https://drive.google.com/uc?id=1fk6r8vetqpRShtEODXm9maDytbMkHLfa' # vgg16.pkl\n",
    "assert is_url(url)\n",
    "assert num_attempts >= 1\n",
    "\n",
    "# Lookup from cache.\n",
    "url_md5 = hashlib.md5(url.encode(\"utf-8\")).hexdigest()\n",
    "if cache_dir is not None:\n",
    "    cache_files = glob.glob(os.path.join(cache_dir, url_md5 + \"_*\"))\n",
    "    if len(cache_files) == 1:\n",
    "        # return open(cache_files[0], \"rb\")\n",
    "        print('a erro')\n",
    "        pass\n",
    "\n",
    "# Download.\n",
    "url_name = None\n",
    "url_data = None\n",
    "with requests.Session() as session:\n",
    "    if verbose:\n",
    "        print(\"Downloading %s ...\" % url, end=\"\", flush=True)\n",
    "    for attempts_left in reversed(range(num_attempts)):\n",
    "        try:\n",
    "            with session.get(url) as res:\n",
    "                res.raise_for_status()\n",
    "                if len(res.content) == 0:\n",
    "                    raise IOError(\"No data received\")\n",
    "\n",
    "                if len(res.content) < 8192:\n",
    "                    content_str = res.content.decode(\"utf-8\")\n",
    "                    if \"download_warning\" in res.headers.get(\"Set-Cookie\", \"\"):\n",
    "                        links = [html.unescape(link) for link in content_str.split('\"') if \"export=download\" in link]\n",
    "                        if len(links) == 1:\n",
    "                            url = requests.compat.urljoin(url, links[0])\n",
    "                            raise IOError(\"Google Drive virus checker nag\")\n",
    "                    if \"Google Drive - Quota exceeded\" in content_str:\n",
    "                        raise IOError(\"Google Drive quota exceeded\")\n",
    "\n",
    "                match = re.search(r'filename=\"([^\"]*)\"', res.headers.get(\"Content-Disposition\", \"\"))\n",
    "                url_name = match[1] if match else url\n",
    "                url_data = res.content\n",
    "                if verbose:\n",
    "                    print(\" done\")\n",
    "                break\n",
    "        except:\n",
    "            if not attempts_left:\n",
    "                if verbose:\n",
    "                    print(\" failed\")\n",
    "                raise\n",
    "            if verbose:\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "\n",
    "# Save to cache.\n",
    "if cache_dir is not None:\n",
    "    safe_name = re.sub(r\"[^0-9a-zA-Z-._]\", \"_\", url_name)\n",
    "    cache_file = os.path.join(cache_dir, url_md5 + \"_\" + safe_name)\n",
    "    temp_file = os.path.join(cache_dir, \"tmp_\" + uuid.uuid4().hex + \"_\" + url_md5 + \"_\" + safe_name)\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    with open(temp_file, \"wb\") as f:\n",
    "        f.write(url_data)\n",
    "    os.replace(temp_file, cache_file) # atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "958bd0bb-57ef-4ee7-b3fb-865059273d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BytesIO at 0x7fa36f924860>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.BytesIO(url_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000abae-84f7-4071-a47b-a0ab78b2666c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
